# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  file {
    path => '/usr/share/data/logs/ea-project-demo.log'
    start_position => 'beginning'
    sincedb_path => '/dev/null'
  }
}

filter {
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} \[%{DATA:thread_name}\] %{JAVACLASS:class} - %{GREEDYDATA:log_message}" 
    }
  }
  
  # Handle specific log messages
  if [log_message] =~ "Traffic data" {
    grok {
      match => { "log_message" => "Traffic data - endpoint: %{DATA:endpoint}, action: %{DATA:action}" }
    }
  } else if [log_message] =~ "executed in" {
    grok {
      match => { "log_message" => "%{DATA:endpoint} executed in %{NUMBER:execution_time} ms" }
    }
  } else if [log_message] =~ "Sales data" {
    grok {
      match => { "log_message" => "Sales data - product: %{DATA:product}, category: %{DATA:category}, quantity: %{NUMBER:quantity}, price: %{NUMBER:price}" }
    }
  }

  if "_grokparsefailure" in [tags] {
    drop { }
  }

    mutate {
    convert => { "quantity" => "integer" }
    convert => { "price" => "float" }
    convert => { "execution_time" => "integer" }
  }

  date {
    match => [ "timestamp", "ISO8601" ]
  }
}



output {
  stdout { codec => rubydebug }
  elasticsearch {
    hosts => ['http://elasticsearch:9200']
    user => elastic
    password => yogen1234
    ssl_certificate_verification => false
    ssl => false
    index => 'elkdemoindex-%{+YYYY.MM.dd}'
  }
}